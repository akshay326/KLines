{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans clustering using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 10**4\n",
    "d = 8\n",
    "k = 4\n",
    "X, y = make_blobs(n_samples=N, n_features=d, centers=k, cluster_std=4.0, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Datapoints: 10000  #Features: 8  #Clusters: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"#Datapoints: {X.shape[0]}  #Features: {X.shape[1]}  #Clusters: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8148223163645895, 0.8147970168390747, 0.8148096664054469)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KMeans(n_clusters = k)\n",
    "clf.fit(X)\n",
    "orig_centroids = clf.cluster_centers_\n",
    "metrics.homogeneity_completeness_v_measure(clf.labels_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans w/ missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_missing(X, n_clusters, max_iter=10):\n",
    "    \"\"\"Perform K-Means clustering on data with missing values.\n",
    "\n",
    "    Args:\n",
    "      X: An [n_samples, n_features] array of data to cluster.\n",
    "      n_clusters: Number of clusters to form.\n",
    "      max_iter: Maximum number of EM iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "      labels: An [n_samples] vector of integer labels.\n",
    "      centroids: An [n_clusters, n_features] array of cluster centroids.\n",
    "      X_hat: Copy of X with the missing values filled in.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize missing values to their column means\n",
    "    missing = ~np.isfinite(X)\n",
    "    mu = np.nanmean(X, 0, keepdims=1)\n",
    "    X_hat = np.where(missing, mu, X)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        if i > 0:\n",
    "            # initialize KMeans with the previous set of centroids. this is much\n",
    "            # faster and makes it easier to check convergence (since labels\n",
    "            # won't be permuted on every iteration), but might be more prone to\n",
    "            # getting stuck in local minima.\n",
    "            cls = KMeans(n_clusters, init=prev_centroids)\n",
    "        else:\n",
    "            # do multiple random initializations in parallel\n",
    "            cls = KMeans(n_clusters)\n",
    "\n",
    "        # perform clustering on the filled-in data\n",
    "        labels = cls.fit_predict(X_hat)\n",
    "        centroids = cls.cluster_centers_\n",
    "\n",
    "        # fill in the missing values based on their cluster centroids\n",
    "        X_hat[missing] = centroids[labels][missing]\n",
    "\n",
    "        # when the labels have stopped changing then we have converged\n",
    "        if i > 0 and np.all(labels == prev_labels):\n",
    "            break\n",
    "\n",
    "        prev_labels = labels\n",
    "        prev_centroids = cls.cluster_centers_\n",
    "\n",
    "    return labels, centroids, X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_incomplete = X.copy()\n",
    "# missing entries indicated with NaN\n",
    "for i in range(X.shape[0]):\n",
    "    X_incomplete[i, np.random.randint(X.shape[1])] = np.nan\n",
    "    \n",
    "# X is the complete data matrix\n",
    "# X_incomplete has the same values as X except a subset have been replace with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay.sharma.mat16.iitbhu/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1035: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n",
      "/home/akshay.sharma.mat16.iitbhu/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1035: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n",
      "/home/akshay.sharma.mat16.iitbhu/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1035: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n",
      "/home/akshay.sharma.mat16.iitbhu/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1035: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "labels, centroids, X_hat = kmeans_missing(X_incomplete, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7489181328862072, 0.7487286279716423, 0.748823368439411)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.homogeneity_completeness_v_measure(labels, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klines MSE: 2.4256941269296792\n"
     ]
    }
   ],
   "source": [
    "klines_mse = ((X - X_hat)**2).mean()\n",
    "print(f\"Klines MSE: {klines_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering using KLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"./KLines\")\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from klines import SetOfLines, SetOfPoints, CoresetForWeightedCenters, CorsetForKMeansForLines, CoresetStreamer\n",
    "\n",
    "displacements = np.nan_to_num(X_incomplete)\n",
    "\n",
    "spans = np.nan_to_num(X_incomplete)\n",
    "spans[spans==0] = 1\n",
    "spans[spans!=1] = 0\n",
    "\n",
    "L = SetOfLines(spans, displacements, np.ones(N), np.ones(N))\n",
    "\n",
    "class ParameterConfig:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "config = ParameterConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "m = d  # coreset size ~ reduction ratio\n",
    "\n",
    "config.a_b_approx_minimum_number_of_lines = 5*d # constant 100, line 2, algo 2 BI-CRITERIA\n",
    "\n",
    "config.sample_size_for_a_b_approx = int(m*1.05) # |S| >= m, line 3 of algo 2\n",
    "                                                # note: there'll be a O(|S|^2) cost while computing algo 1\n",
    "    \n",
    "config.farthest_to_centers_rate_in_a_b_approx = 0.2  # opp of 7/11, line 6, algo 2 BI-CRITERIA\n",
    "config.number_of_remains_multiply_factor = 3 # this is `b` in algo 2, other paper, set as random here -  how to calculate it?\n",
    "config.closest_to_median_rate = 0.25  # refer line 4, algo 1, other paper\n",
    "\n",
    "config.median_sample_size = 20    # size of q_i, line 3, algo 2, other paper\n",
    "config.max_sensitivity_multiply_factor = 100  # for outliers in coresets\n",
    "\n",
    "config.number_of_remains = 20\n",
    "\n",
    "SAMPLE_SIZE = 4*d   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./KLines/klines/set_of_lines.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  s_c = be_minus_cd / ac_minus_b_squared\n",
      "./KLines/klines/set_of_lines.py:455: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sensitivities_first_argument = all_distances_min / cost_to_B\n",
      "./KLines/klines/set_of_lines.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  s_c = be_minus_cd / ac_minus_b_squared\n",
      "./KLines/klines/set_of_lines.py:455: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sensitivities_first_argument = all_distances_min / cost_to_B\n",
      "./KLines/klines/set_of_lines.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  s_c = be_minus_cd / ac_minus_b_squared\n",
      "./KLines/klines/set_of_lines.py:455: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sensitivities_first_argument = all_distances_min / cost_to_B\n",
      "./KLines/klines/set_of_lines.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  s_c = be_minus_cd / ac_minus_b_squared\n",
      "./KLines/klines/set_of_lines.py:455: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sensitivities_first_argument = all_distances_min / cost_to_B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klines MSE: 6.289071210103633\n",
      "Scores: [0.33786542 0.33552776 0.33669253]\n"
     ]
    }
   ],
   "source": [
    "def pp():\n",
    "    streamer = CoresetStreamer(SAMPLE_SIZE, k, config)\n",
    "    coreset = streamer.stream(L)\n",
    "    L1 = coreset[0]\n",
    "    \n",
    "    _, B, _ = CorsetForKMeansForLines(config).coreset(L1, k, m, True)\n",
    "    cwc = CoresetForWeightedCenters(config)\n",
    "    B = cwc.coreset(B, k, m)\n",
    "\n",
    "    X_klines = L.get_projected_centers(B)    \n",
    "    kl_labels = L.get_indices_clusters(B)\n",
    "    \n",
    "    return X_klines, kl_labels\n",
    "\n",
    "\n",
    "klines_mse = []\n",
    "scores = []\n",
    "ITER = 5\n",
    "for i in range(ITER):\n",
    "    X_klines, kl_labels = pp()\n",
    "    klines_mse.append(((X - X_klines)**2).mean())\n",
    "    \n",
    "    kl_labels = L.get_indices_clusters(B)\n",
    "    scores.append(metrics.homogeneity_completeness_v_measure(kl_labels, y))\n",
    "\n",
    "print(f\"Klines MSE: {np.array(klines_mse).mean()}\")\n",
    "print(f\"Scores: {np.array(scores).mean(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
